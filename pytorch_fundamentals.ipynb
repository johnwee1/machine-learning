{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 27,  30,  33],\n",
       "        [ 61,  68,  75],\n",
       "        [ 95, 106, 117]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([[1,2],\n",
    "                  [3,4],\n",
    "                  [5,6]])\n",
    "b = torch.tensor([[7,10],\n",
    "                  [8,11],\n",
    "                  [9,12]]).T # transposed\n",
    "\n",
    "torch.mm(a,b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0, 10, 20, 30, 40, 50, 60, 70, 80, 90])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the min max mean sum (tensor aggregation)\n",
    "\n",
    "x = torch.arange(0,100,10)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean(): could not infer output dtype. Input dtype must be either a floating point or complex dtype. Got: Long\n",
      "tensor([[0.0732, 0.6118, 0.1433],\n",
      "        [0.8185, 0.1660, 0.1044],\n",
      "        [0.2663, 0.9620, 0.4651]])\n",
      "tensor(0)\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    y = torch.mean(x)\n",
    "except RuntimeError as e:\n",
    "    print(e)\n",
    "\n",
    "z = torch.mean(x.type(torch.float32))\n",
    "# print(z)\n",
    "\n",
    "rand_tensor = torch.rand(3,3)\n",
    "arg = torch.argmin(rand_tensor) # find the POSITION in tensor that hias min value with argmin\n",
    "print(rand_tensor)\n",
    "print(arg) # for nd arrays it flattens the array, if no axis is specified.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshaping - reshapes input etensor to a defined shape\n",
    "# returns view of input tensor but keep the same memory as original\n",
    "# stack --> vstack, hstack to combine multkple tensors\n",
    "# squeeze removes all 1 dimensions from a tensor\n",
    "# unsqueeze\n",
    "# permute - return a view with dimensions permuted in some way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2., 3., 4., 5., 6., 7., 8., 9.],\n",
       "        [1., 2., 3., 4., 5., 6., 7., 8., 9.],\n",
       "        [1., 2., 3., 4., 5., 6., 7., 8., 9.]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(1.,10.)\n",
    "x, x.shape\n",
    "x_reshaped = x.reshape(1,9)\n",
    "x_reshaped, x_reshaped.shape\n",
    "\n",
    "# change view \n",
    "z = x.view(1,9)\n",
    "z,z.shape\n",
    "\n",
    "# changing z changes x because they share the same underlying memory \n",
    "x = torch.stack([x,x,x],dim=0)\n",
    "x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2., 3., 4., 5., 6., 7.])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([[1,2,3,4,5,6,7]], dtype=torch.float32)\n",
    "x = x.squeeze()\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.],\n",
       "        [2.],\n",
       "        [3.],\n",
       "        [4.],\n",
       "        [5.],\n",
       "        [6.],\n",
       "        [7.]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.unsqueeze(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.3250, 0.2429, 0.7514],\n",
       "         [0.9503, 0.7913, 0.7512],\n",
       "         [0.4087, 0.7426, 0.4522],\n",
       "         ...,\n",
       "         [0.2709, 0.1351, 0.9051],\n",
       "         [0.6959, 0.8442, 0.0909],\n",
       "         [0.3345, 0.8435, 0.7566]],\n",
       "\n",
       "        [[0.3956, 0.0790, 0.7129],\n",
       "         [0.4732, 0.5424, 0.0358],\n",
       "         [0.3056, 0.5847, 0.6390],\n",
       "         ...,\n",
       "         [0.0132, 0.2523, 0.2055],\n",
       "         [0.7829, 0.7802, 0.4393],\n",
       "         [0.7086, 0.3715, 0.5788]],\n",
       "\n",
       "        [[0.1046, 0.4171, 0.5705],\n",
       "         [0.8626, 0.9808, 0.8428],\n",
       "         [0.9548, 0.7249, 0.5164],\n",
       "         ...,\n",
       "         [0.7302, 0.0485, 0.4786],\n",
       "         [0.1145, 0.9048, 0.3317],\n",
       "         [0.3166, 0.6589, 0.4174]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.0580, 0.1241, 0.1869],\n",
       "         [0.3697, 0.3328, 0.4620],\n",
       "         [0.0257, 0.1942, 0.7322],\n",
       "         ...,\n",
       "         [0.8622, 0.3394, 0.7384],\n",
       "         [0.0084, 0.0332, 0.4968],\n",
       "         [0.4119, 0.0995, 0.2165]],\n",
       "\n",
       "        [[0.5572, 0.9640, 0.7800],\n",
       "         [0.8617, 0.5282, 0.5493],\n",
       "         [0.8708, 0.1723, 0.9525],\n",
       "         ...,\n",
       "         [0.0720, 0.6285, 0.1435],\n",
       "         [0.6669, 0.3919, 0.9521],\n",
       "         [0.0474, 0.0157, 0.6902]],\n",
       "\n",
       "        [[0.5440, 0.0599, 0.6772],\n",
       "         [0.5713, 0.0028, 0.8667],\n",
       "         [0.8056, 0.9219, 0.2230],\n",
       "         ...,\n",
       "         [0.8655, 0.4174, 0.9063],\n",
       "         [0.4893, 0.5668, 0.9219],\n",
       "         [0.3601, 0.0886, 0.3647]]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_ori = torch.rand(size=(224,224,3))\n",
    "x_permuted = x_ori.permute(2,0,1) # shifts axis 0->1, 1->2, 2->0\n",
    "x_ori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# indexing\n",
    "# selecting data from tensors\n",
    "# index with pytorch is same with indexing with numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[1, 2, 3],\n",
       "          [4, 5, 6],\n",
       "          [7, 8, 9]]]),\n",
       " torch.Size([1, 3, 3]))"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(1,10).reshape(1,3,3)\n",
    "x, x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [4, 5, 6],\n",
       "        [7, 8, 9]])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# index on the new tensor\n",
    "x[0] # 0th index of the outermost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0][0]\n",
    "# middle bracket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Indexing on the inner bracket\n",
    "x[0][0][2]\n",
    "# out of \n",
    "#(1, 3, 3) <-- shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4, 5, 6]])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x\n",
    "x[:, 1]\n",
    "#all, 1, X, kinda like a wildcard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2, 5, 8]])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[:, :, 1]\n",
    "# slightly different from x[0,0,1] beacuse the colon adds a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0,0,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pytorch and numpy\n",
    "numpy and pytorch can interact with each other\n",
    "cast from ndarray to tensor --> torch.from_numpy(ndarray)\n",
    "cast tensor to numpy with numpy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2., 3., 4., 5., 6., 7., 8., 9.])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "array = np.arange(1,10,1,dtype=np.float32)\n",
    "\n",
    "tensor = torch.from_numpy(array) # when converting from np to torch python defaults to default np64 bit unless otherwise specified\n",
    "tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float32')"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "back_to_array = tensor.numpy()\n",
    "\n",
    "back_to_array.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pytorch reproducibility (taking randomness out of random using seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 1001\n",
    "# need to set the manual seed for every function call\n",
    "\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "rand_a = torch.rand(3,4)\n",
    "\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "rand_b = torch.rand(3,4)\n",
    "\n",
    "rand_a, rand_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup device agnostic code\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3]) cpu\n"
     ]
    }
   ],
   "source": [
    "# Putting tensors and models on the GPU\n",
    "tensor = torch.tensor([1,2,3])\n",
    "print(tensor, tensor.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_on_gpu = tensor.to(device) # init such that device uses GPU if avail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if tensor is on GPU cant transform it to numpy\n",
    "tensor_on_cpu = tensor_on_gpu.cpu().numpy()\n",
    "tensor_on_cpu"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
